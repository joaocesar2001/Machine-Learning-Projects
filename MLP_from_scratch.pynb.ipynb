{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabae52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class NnModel:\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray, hidden_neurons: int = 10, output_neurons: int = 2):\n",
    "        np.random.seed(8)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.output_neurons = output_neurons\n",
    "        self.input_neurons = self.x.shape[1]\n",
    "\n",
    "        # Inicializa os pesos e bias\n",
    "        # Xavier Inicialization -> Variancia dos pesos igual em todas as camadas \n",
    "        # -> divide tudo por np.sqrt(self.input_neurons)\n",
    "\n",
    "        self.W1 = np.random.randn(self.input_neurons, self.hidden_neurons) / np.sqrt(self.input_neurons)\n",
    "        self.B1 = np.zeros((1, self.hidden_neurons))\n",
    "        self.W2 = np.random.randn(self.hidden_neurons, self.output_neurons) / np.sqrt(self.hidden_neurons)\n",
    "        self.B2 = np.zeros((1, self.output_neurons))\n",
    "        self.model_dict = {\"W1\": self.W1, \"B1\": self.B1, \"W2\": self.W2, \"B2\": self.B2}\n",
    "        self.z1 = 0\n",
    "        self.f1 = 0\n",
    "\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        # Equação da reta\n",
    "        self.z1 = x.dot(self.W1) + self.B1\n",
    "\n",
    "        # Função de ativação (1)\n",
    "\n",
    "        self.f1 = np.tanh(self.z1)\n",
    "\n",
    "        # Equação da reta (2)\n",
    "        z2 = self.f1.dot(self.W2) + self.B2\n",
    "\n",
    "     \n",
    "\n",
    "        #Softmax\n",
    "        exp_values = np.exp(z2)\n",
    "        softmax = exp_values / np.sum(exp_values, axis = 1, keepdims = True) #soma da linha e não do array todo\n",
    "        return softmax\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def loss(self, softmax):\n",
    "        # Cross Entropy\n",
    "\n",
    "        predictions = np.zeros(self.y.shape[0])\n",
    "\n",
    "        for i, correct_index in enumerate(self.y):\n",
    "            predicted = softmax[i][correct_index] #pega o valor do softmax e seu index\n",
    "            predictions[i] = predicted\n",
    "\n",
    "        log_prob = -np.log(predicted)\n",
    "        return log_prob/self.y.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def backpropagation(self, softmax: np.ndarray, learning_rate: float) -> None:\n",
    "        delta2 = np.copy(softmax)\n",
    "        delta2[range(self.x.shape[0]), self.y] -= 1\n",
    "\n",
    "        dW2 = (self.f1.T).dot(delta2)\n",
    "        dB2 = np.sum(delta2, axis = 0, keepdims = True)\n",
    "\n",
    "        delta1 = delta2.dot(self.W2.T)*(1-np.power(np.tanh(self.z1),2))\n",
    "        dW1 = (self.x.T).dot(delta1)\n",
    "        dB1 = np.sum(delta1)\n",
    "\n",
    "        #atualização dos pesos e bias\n",
    "\n",
    "        self.W1 += - learning_rate*dW1\n",
    "        self.W2 += - learning_rate*dW2\n",
    "        self.B1 += - learning_rate*dB1\n",
    "        self.B2 += - learning_rate*dB2\n",
    "        \n",
    "    def show_plot(self, predictions):\n",
    "        if self.x.shape[1] == 2:\n",
    "            plt.scatter(self.x[:,0], self.x[:,1], s=50, c = predictions, cmap=\"cool\", alpha=0.7)\n",
    "            plt.show()\n",
    "        elif self.x.shape[1] == 3:\n",
    "            ax = plt.axes(projection = \"3d\")\n",
    "            ax.scatter3D(x_[:,0],x_[:,1],x_[:,2], s=40, c=predictions, cmap=\"cool\", alpha=0.8)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    def fit(self, epochs: int, lr: float, show_plot: bool = False):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            outputs = self.forward(self.x)\n",
    "            loss = self.loss(outputs)\n",
    "            \n",
    "            self.backpropagation(outputs, lr)\n",
    "\n",
    "            # Acuracia \n",
    "            prediction = np.argmax(outputs, axis = 1)\n",
    "            correct = (prediction == self.y).sum()\n",
    "            accuracy = correct/self.y.shape[0]\n",
    "\n",
    "            if int((epoch+1) % (epochs/10)) == 0:\n",
    "                print(f\"Epoch: [{epoch + 1} / {epochs}] Accuracy: {accuracy:.3f} Loss: {loss.item():.5f}\")\n",
    "                if show_plot:\n",
    "                    self.show_plot(prediction)\n",
    "        return prediction\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
